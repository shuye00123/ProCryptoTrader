#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸‹è½½Binanceè‡ª2018å¹´ä»¥æ¥æ‰€æœ‰äº¤æ˜“å¯¹çš„æ—¥çº¿æ•°æ®
æ³¨æ„ï¼šè¿™æ˜¯ä¸€ä¸ªå¤§è§„æ¨¡æ•°æ®ä¸‹è½½ä»»åŠ¡ï¼Œå¯èƒ½éœ€è¦æ•°å°æ—¶å®Œæˆ
"""

import os
import sys
import time
import signal
from pathlib import Path
from datetime import datetime, timedelta
from typing import List, Dict, Set
import json

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from core.data.data_fetcher import DataFetcher
from core.data.data_manager import DataManager
from core.utils.logger import get_logger

logger = get_logger("DownloadAllBinanceData")

# å…¨å±€å˜é‡ç”¨äºä¼˜é›…é€€å‡º
is_interrupted = False
download_stats = {
    'total_symbols': 0,
    'successful_downloads': 0,
    'failed_downloads': 0,
    'start_time': None,
    'end_time': None,
    'failed_symbols': [],
    'processed_symbols': []
}

def signal_handler(signum, frame):
    """å¤„ç†ä¸­æ–­ä¿¡å·"""
    global is_interrupted
    is_interrupted = True
    print("\n\nâš ï¸  æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨ä¼˜é›…é€€å‡º...")
    print("å·²å®Œæˆçš„ä¸‹è½½ä¿¡æ¯å°†è¢«ä¿å­˜")


def get_active_symbols(fetcher: DataFetcher, min_volume: float = 1000000) -> List[str]:
    """
    è·å–æ´»è·ƒçš„äº¤æ˜“å¯¹åˆ—è¡¨

    Args:
        fetcher: DataFetcherå®ä¾‹
        min_volume: æœ€å°24å°æ—¶äº¤æ˜“é‡ï¼ˆUSDTï¼‰

    Returns:
        æ´»è·ƒäº¤æ˜“å¯¹åˆ—è¡¨
    """
    print("ğŸ“Š è·å–Binanceäº¤æ˜“å¯¹ä¿¡æ¯...")

    try:
        # è·å–å¸‚åœºä¿¡æ¯
        markets = fetcher.get_exchange_info()

        active_symbols = []
        for symbol, info in markets.items():
            # åªé€‰æ‹©USDTäº¤æ˜“å¯¹
            if not symbol.endswith('/USDT'):
                continue

            # åªé€‰æ‹©ç°è´§äº¤æ˜“å¯¹
            if info.get('type') != 'spot':
                continue

            # åªé€‰æ‹©æ´»è·ƒçš„äº¤æ˜“å¯¹
            if not info.get('active', False):
                continue

            # è¿‡æ»¤æ‰ç¨³å®šå¸å¯¹å’Œç‰¹æ®Šç¬¦å·
            quote = symbol.split('/')[1]
            if quote in ['BUSD', 'USDC', 'TUSD', 'PAX', 'USDP']:
                continue

            # è¿‡æ»¤æ‰ä¸€äº›ç‰¹æ®Šç¬¦å·
            base = symbol.split('/')[0]
            if any(char in base for char in ['UP', 'DOWN', 'BEAR', 'BULL']):
                continue

            active_symbols.append(symbol)

        # æŒ‰å­—æ¯é¡ºåºæ’åº
        active_symbols.sort()

        print(f"âœ“ æ‰¾åˆ° {len(active_symbols)} ä¸ªæ´»è·ƒçš„USDTäº¤æ˜“å¯¹")
        return active_symbols

    except Exception as e:
        logger.error(f"è·å–äº¤æ˜“å¯¹ä¿¡æ¯å¤±è´¥: {e}")
        # å¦‚æœè·å–å¤±è´¥ï¼Œè¿”å›ä¸€äº›çƒ­é—¨äº¤æ˜“å¯¹
        fallback_symbols = [
            'BTC/USDT', 'ETH/USDT', 'BNB/USDT', 'SOL/USDT', 'ADA/USDT',
            'XRP/USDT', 'DOGE/USDT', 'AVAX/USDT', 'DOT/USDT', 'MATIC/USDT',
            'LINK/USDT', 'UNI/USDT', 'LTC/USDT', 'BCH/USDT', 'FIL/USDT',
            'ETC/USDT', 'XLM/USDT', 'VET/USDT', 'THETA/USDT', 'TRX/USDT',
            'ICP/USDT', 'SHIB/USDT', 'FTM/USDT', 'NEAR/USDT', 'ATOM/USDT'
        ]
        print(f"âš ï¸  è·å–å¸‚åœºä¿¡æ¯å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤çš„ {len(fallback_symbols)} ä¸ªçƒ­é—¨äº¤æ˜“å¯¹")
        return fallback_symbols


def download_symbol_data(manager: DataManager, fetcher: DataFetcher, symbol: str,
                        start_date: str, end_date: str, timeframe: str = '1d') -> bool:
    """
    ä¸‹è½½å•ä¸ªäº¤æ˜“å¯¹çš„æ•°æ®

    Args:
        manager: DataManagerå®ä¾‹
        fetcher: DataFetcherå®ä¾‹
        symbol: äº¤æ˜“å¯¹
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
        timeframe: æ—¶é—´æ¡†æ¶

    Returns:
        æ˜¯å¦ä¸‹è½½æˆåŠŸ
    """
    try:
        # æ£€æŸ¥æ•°æ®æ˜¯å¦å·²å­˜åœ¨
        existing_data = manager.load_data(symbol, timeframe, start_date, end_date)
        if not existing_data.empty:
            expected_days = (datetime.strptime(end_date, '%Y-%m-%d') -
                           datetime.strptime(start_date, '%Y-%m-%d')).days + 1
            if len(existing_data) >= expected_days * 0.95:  # 95%å®Œæ•´åº¦
                print(f"  âœ“ {symbol} æ•°æ®å·²å­˜åœ¨ ({len(existing_data)} æ¡)")
                return True

        print(f"  â¬‡ï¸  æ­£åœ¨ä¸‹è½½ {symbol} æ—¥çº¿æ•°æ®...")

        # ä¸‹è½½æ•°æ®
        result = manager.download_historical_data(symbol, timeframe, start_date, end_date)

        if result:
            # éªŒè¯ä¸‹è½½æ•°æ®
            data = manager.load_data(symbol, timeframe, start_date, end_date)
            if not data.empty:
                print(f"  âœ“ {symbol} ä¸‹è½½æˆåŠŸ ({len(data)} æ¡æ•°æ®)")
                download_stats['successful_downloads'] += 1
                download_stats['processed_symbols'].append(symbol)
                return True
            else:
                print(f"  âœ— {symbol} ä¸‹è½½åæ•°æ®ä¸ºç©º")
                download_stats['failed_downloads'] += 1
                download_stats['failed_symbols'].append(symbol)
                return False
        else:
            print(f"  âœ— {symbol} ä¸‹è½½å¤±è´¥")
            download_stats['failed_downloads'] += 1
            download_stats['failed_symbols'].append(symbol)
            return False

    except Exception as e:
        logger.error(f"ä¸‹è½½ {symbol} æ•°æ®æ—¶å‡ºé”™: {e}")
        print(f"  âœ— {symbol} ä¸‹è½½å‡ºé”™: {str(e)[:50]}...")
        download_stats['failed_downloads'] += 1
        download_stats['failed_symbols'].append(symbol)
        return False


def save_progress_stats():
    """ä¿å­˜ä¸‹è½½è¿›åº¦ç»Ÿè®¡"""
    stats_file = project_root / "data" / "download_stats.json"
    stats_file.parent.mkdir(parents=True, exist_ok=True)

    # æ·»åŠ æ—¶é—´æˆ³
    download_stats['end_time'] = datetime.now().isoformat()
    if download_stats['start_time']:
        duration = datetime.now() - download_stats['start_time']
        download_stats['duration_seconds'] = duration.total_seconds()
        download_stats['duration_formatted'] = str(duration).split('.')[0]

    try:
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump(download_stats, f, indent=2, ensure_ascii=False)
        print(f"\nğŸ“Š ä¸‹è½½ç»Ÿè®¡å·²ä¿å­˜åˆ°: {stats_file}")
    except Exception as e:
        logger.error(f"ä¿å­˜ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•°"""
    global download_stats

    # æ³¨å†Œä¿¡å·å¤„ç†å™¨
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)

    print("=" * 80)
    print("ğŸš€ Binance å…¨é‡å†å²æ•°æ®ä¸‹è½½å·¥å…·")
    print("   ä¸‹è½½è‡ª2018å¹´ä»¥æ¥æ‰€æœ‰æ´»è·ƒäº¤æ˜“å¯¹çš„æ—¥çº¿æ•°æ®")
    print("=" * 80)

    # é…ç½®å‚æ•°
    data_dir = project_root / "data" / "binance"
    data_dir.mkdir(parents=True, exist_ok=True)

    start_date = "2018-01-01"
    end_date = datetime.now().strftime('%Y-%m-%d')
    timeframe = "1d"

    print(f"ğŸ“ æ•°æ®ç›®å½•: {data_dir}")
    print(f"ğŸ“… æ—¶é—´èŒƒå›´: {start_date} è‡³ {end_date}")
    print(f"â° æ—¶é—´æ¡†æ¶: {timeframe}")

    try:
        # åˆå§‹åŒ–æ•°æ®è·å–å™¨å’Œç®¡ç†å™¨
        print("\nğŸ”§ åˆå§‹åŒ–æ•°æ®è·å–å™¨...")
        fetcher = DataFetcher('binance', enable_rate_limit=True)
        # ä¿®æ”¹ä¸ºç°è´§äº¤æ˜“
        fetcher.exchange.options['defaultType'] = 'spot'
        manager = DataManager(str(data_dir), 'binance')

        # è·å–æ´»è·ƒäº¤æ˜“å¯¹åˆ—è¡¨
        symbols = get_active_symbols(fetcher)
        download_stats['total_symbols'] = len(symbols)
        download_stats['start_time'] = datetime.now()

        print(f"\nğŸ¯ å‡†å¤‡ä¸‹è½½ {len(symbols)} ä¸ªäº¤æ˜“å¯¹çš„æ—¥çº¿æ•°æ®")
        print(f"â±ï¸  é¢„è®¡è€—æ—¶: {len(symbols) * 2:.0f} åˆ†é’Ÿ (æŒ‰æ¯ä¸ªäº¤æ˜“å¯¹2åˆ†é’Ÿä¼°ç®—)")

        # ç¡®è®¤æ˜¯å¦ç»§ç»­
        user_input = input("\næ˜¯å¦ç»§ç»­ä¸‹è½½ï¼Ÿ(y/N): ").strip().lower()
        if user_input not in ['y', 'yes']:
            print("ä¸‹è½½å·²å–æ¶ˆ")
            return 0

        # å¼€å§‹ä¸‹è½½
        print(f"\nğŸš€ å¼€å§‹ä¸‹è½½ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("-" * 80)

        batch_size = 10  # æ¯æ‰¹å¤„ç†10ä¸ªäº¤æ˜“å¯¹
        batch_delay = 30  # æ‰¹æ¬¡é—´å»¶è¿Ÿ30ç§’ï¼ˆé¿å…APIé™åˆ¶ï¼‰

        for i in range(0, len(symbols), batch_size):
            if is_interrupted:
                break

            batch = symbols[i:i + batch_size]
            batch_num = i // batch_size + 1
            total_batches = (len(symbols) + batch_size - 1) // batch_size

            print(f"\nğŸ“¦ æ‰¹æ¬¡ {batch_num}/{total_batches}: {', '.join(batch)}")

            # å¤„ç†å½“å‰æ‰¹æ¬¡
            for symbol in batch:
                if is_interrupted:
                    break

                success = download_symbol_data(manager, fetcher, symbol, start_date, end_date, timeframe)

                # æ¯ä¸ªäº¤æ˜“å¯¹é—´å»¶è¿Ÿï¼Œé¿å…è§¦å‘APIé™åˆ¶
                if symbol != batch[-1]:  # ä¸æ˜¯æ‰¹æ¬¡ä¸­æœ€åä¸€ä¸ª
                    time.sleep(2)

            # æ‰¹æ¬¡é—´å»¶è¿Ÿ
            if i + batch_size < len(symbols) and not is_interrupted:
                print(f"â³ ç­‰å¾… {batch_delay} ç§’ä»¥é¿å…APIé™åˆ¶...")
                for remaining in range(batch_delay, 0, -1):
                    if is_interrupted:
                        break
                    print(f"   {remaining} ç§’", end='\r')
                    time.sleep(1)
                print()  # æ¢è¡Œ

        # è¾“å‡ºæœ€ç»ˆç»Ÿè®¡
        print("\n" + "=" * 80)
        print("ğŸ“Š ä¸‹è½½å®Œæˆç»Ÿè®¡:")
        print(f"   æ€»äº¤æ˜“å¯¹æ•°: {download_stats['total_symbols']}")
        print(f"   æˆåŠŸä¸‹è½½: {download_stats['successful_downloads']}")
        print(f"   ä¸‹è½½å¤±è´¥: {download_stats['failed_downloads']}")
        print(f"   æˆåŠŸç‡: {(download_stats['successful_downloads'] / download_stats['total_symbols'] * 100):.1f}%")

        if download_stats['failed_symbols']:
            print(f"\nâŒ å¤±è´¥çš„äº¤æ˜“å¯¹:")
            for symbol in download_stats['failed_symbols'][:20]:  # åªæ˜¾ç¤ºå‰20ä¸ª
                print(f"   - {symbol}")
            if len(download_stats['failed_symbols']) > 20:
                print(f"   ... è¿˜æœ‰ {len(download_stats['failed_symbols']) - 20} ä¸ª")

        # åˆ—å‡ºå·²ä¸‹è½½çš„æ•°æ®
        available_data = manager.list_available_data()
        print(f"\nğŸ“ å·²ä¸‹è½½çš„æ•°æ®ç›®å½•: {data_dir}")
        print(f"   äº¤æ˜“å¯¹æ•°é‡: {len(available_data)}")

        total_size = 0
        for symbol, timeframes in available_data.items():
            for timeframe in timeframes:
                file_path = manager._get_file_path(symbol, timeframe)
                if os.path.exists(file_path):
                    total_size += os.path.getsize(file_path)

        if total_size > 0:
            print(f"   æ€»æ•°æ®å¤§å°: {total_size / 1024 / 1024:.1f} MB")

        # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
        save_progress_stats()

        if is_interrupted:
            print("\nâš ï¸  ä¸‹è½½è¢«ä¸­æ–­")
            print("ğŸ’¡ æç¤ºï¼šå¯ä»¥é‡æ–°è¿è¡Œæ­¤è„šæœ¬ç»§ç»­ä¸‹è½½")
            return 1
        else:
            print("\nğŸ‰ æ‰€æœ‰æ•°æ®ä¸‹è½½å®Œæˆï¼")
            return 0

    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­ä¸‹è½½")
        save_progress_stats()
        return 1
    except Exception as e:
        logger.error(f"ä¸‹è½½è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        print(f"\nâŒ ä¸‹è½½å¤±è´¥: {e}")
        save_progress_stats()
        return 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)